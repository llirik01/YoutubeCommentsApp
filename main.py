import streamlit as st
from youtubeAPI import *
from sentiment_analysis import *
from frequency_analysis import *
import time

api_key = 'AIzaSyA40tswEwzrSr5HrxvescQLz06S9pQXtfo'

st.set_page_config(page_title='YouTubeCommentsApp', layout='wide')

st.logo('logo.png', size="large")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å—Ç–∞–Ω—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏, —è–∫—â–æ —â–µ –Ω–µ –∑–∞–¥–∞–Ω–æ
if "page" not in st.session_state:
    st.session_state["page"] = "home"  # –ü–æ—á–∞—Ç–∫–æ–≤–∏–π –µ–∫—Ä–∞–Ω

if "primary_df" not in st.session_state:
    st.session_state["primary_df"] = None

if "df_clean_sentiment" not in st.session_state:
    st.session_state["df_clean_sentiment"] = None

if "df_sentiment" not in st.session_state:
    st.session_state["df_sentiment"] = None  # pd.DataFrame()

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –ø–µ—Ä–µ–º–∏–∫–∞–Ω–Ω—è –º—ñ–∂ –µ–∫—Ä–∞–Ω–∞–º–∏
def set_page(page_name):
    st.session_state["page"] = page_name


# **–°–∞–π–¥–±–∞—Ä –∑ –∫–Ω–æ–ø–∫–∞–º–∏**
with st.sidebar:
    if st.button("Homepage", use_container_width=True):
        set_page("home")

    st.divider()

    link = st.text_input("", placeholder="Paste your link here", label_visibility="hidden")
    submit_button = st.button("Pass the link", use_container_width=True)

    if submit_button and link:
        # –û—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö –¥–∞–Ω–∏—Ö –ø–µ—Ä–µ–¥ –Ω–æ–≤–∏–º –∑–∞–ø–∏—Ç–æ–º
        st.session_state.primary_df = None
        st.session_state.df_clean_sentiment = None
        st.session_state.df_sentiment = None

        with st.spinner("Fetching comments..."):
            time.sleep(3)
            primary_df = get_comments(api_key=api_key, video_url=link)

        if primary_df is None:
            st.error("Please insert a link before submitting.", icon='‚ùóÔ∏è')
        else:
            with st.spinner("Cleaning data for sentiment analysis..."):
                time.sleep(3)
                df_clean_sentiment = clean_df_for_sentiment(primary_df)

            with st.spinner("Performing sentiment analysis..."):
                df_sentiment = make_sentiment_analysis(df_clean_sentiment)

            st.session_state["primary_df"] = primary_df
            st.session_state['df_clean_sentiment'] = df_clean_sentiment
            st.session_state["df_sentiment"] = df_sentiment
            st.success(f'Analysis complete! {len(primary_df)} comments found', icon="‚úÖ")

    st.text(' ')
    st.text(' ')
    st.text(' ')
    st.header("App`s functionality", divider=True)

    if st.button("Top-100 most liked comments", use_container_width=True):
        set_page("function_1")
    if st.button("Top-100 most positive comments", use_container_width=True):
        set_page("function_2")
    if st.button("Top-100 most negative comments", use_container_width=True):
        set_page("function_3")
    if st.button("Show all comments", use_container_width=True):
        set_page("function_4")
    if st.button("Sentiment visualization", use_container_width=True):
        set_page("function_5")
    if st.button("Frequent words visualization", use_container_width=True):
        set_page("function_6")

    st.divider()
    st.markdown("<h5 style='text-align: center; color: black; font-weight: normal;'>Created by Kyryl Shum üßë‚Äçüíª</h5>",
                unsafe_allow_html=True)

# **–ì–æ–ª–æ–≤–Ω–∏–π –µ–∫—Ä–∞–Ω**
if st.session_state["page"] == "home":
    st.markdown("<h1 style='font-family: san-serif; text-align: center; color: black; \
     font-weight: 650;'>üì∫ YouTube Comment Analysis</h1>", unsafe_allow_html=True)

    st.markdown("<h2 style='font-family: san-serif; text-align: left; color: #261324; \
         font-weight: 550;'>üéØ Purpose of the Application</h2>", unsafe_allow_html=True)

    st.markdown("<p style='font-family: san-serif; text-align: justify; color: #261324; \
             font-weight: normal; font-size: 20px'>This application is designed for the automatic analysis of \
             comments under YouTube videos. It allows users to easily retrieve, process, and examine comments, \
             identifying key trends, emotional tone, and frequently used words. The tool is useful for bloggers, \
             marketers, analysts, and anyone who wants to gain deeper insights into audience opinions.</p>",
                unsafe_allow_html=True)

    st.markdown("<h2 style='font-family: san-serif; text-align: left; color: black; \
             font-weight: 550;'>üìä Sentiment Analysis</h2>", unsafe_allow_html=True)

    st.markdown("<p style='font-family: san-serif; text-align: justify; color: black; \
                 font-weight: normal; font-size: 20px'>Sentiment analysis is used to automatically determine \
                 the emotional tone of comments. Each comment can be classified as positive, negative, or neutral. \
                 It is important to note that this classification does not necessarily reflect the audience's \
                 attitude toward the video creator but rather indicates general public sentiment regarding the \
                 discussed topic. For example, negative comments may express emotions such as sadness, regret, \
                 sympathy, or dissatisfaction. Similarly, positive comments may convey joy, support, hope, or \
                 admiration.</p>", unsafe_allow_html=True)

    st.markdown("<p style='font-family: san-serif; text-align: justify; color: black; \
                     font-weight: normal; font-size: 20px'>It is also important to consider that classification \
                     models may not always accurately recognize sarcastic or ironic statements. As a result, \
                     such messages may be mistakenly categorized into a different sentiment group, which should \
                     be considered when interpreting the analysis results.</p>", unsafe_allow_html=True)

    st.markdown("<h2 style='font-family: san-serif; text-align: left; color: black; \
                    font-weight: 550;'>üîç Frequency Analysis</h2>", unsafe_allow_html=True)

    st.markdown("<p style='font-family: san-serif; text-align: justify; color: black; \
                         font-weight: normal; font-size: 20px'>Frequency analysis helps identify the most \
                         commonly used words in comments. This allows users to understand what topics or events \
                         are being most discussed by the audience. Through this analysis, users can quickly \
                         highlight key trends in comments and gain deeper insights into audience reactions or \
                         the topics being discussed in the video.</p>", unsafe_allow_html=True)

    st.markdown("<h2 style='font-family: san-serif; text-align: left; color: black; \
                        font-weight: 550;'>üî§ Supported Languages</h2>", unsafe_allow_html=True)

    st.markdown("<p style='font-family: san-serif; text-align: justify; color: black; \
                         font-weight: normal; font-size: 20px'>The application can analyze comments in 23 languages:  \
                         English (en), Ukrainian (uk), French (fr), German (de), Italian (it), Japanese (ja), \
                         Korean (ko), Polish (pl), Portuguese (pt), Russian (ru), Spanish (es), Swedish (sv), \
                         Romanian (ro), Dutch (nl), Croatian (hr), Greek (el), Slovenian (sl), Norwegian Bokm√•l (nb), \
                         Macedonian (mk), Lithuanian (lt), Finnish (fi), Danish (da), Catalan (ca).",
                unsafe_allow_html=True)

    st.markdown("<p style='font-family: san-serif; text-align: left; text-align: justify; color: black; \
                        font-weight: 550; font-size: 24px'> üì¢ Let's start analyzing! Paste the video link and \
                        get a detailed comment analysis.</p>", unsafe_allow_html=True)




# **–§—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ –µ–∫—Ä–∞–Ω–∏**
elif st.session_state["page"] == "function_1":
    st.markdown("<h2 style='font-family: san-serif; text-align: center; color: #261324; \
             font-weight: 550;'>Top-100 most liked comments</h2>", unsafe_allow_html=True)

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö
    if "df_sentiment" not in st.session_state or st.session_state["df_sentiment"] is None:
        st.warning("No data available. Please provide a link and fetch comments first.", icon='‚ö†Ô∏è')
    else:
        toplikes_df = top_liked_comments(st.session_state["df_sentiment"])
        st.dataframe(data=toplikes_df, use_container_width=True)

elif st.session_state["page"] == "function_2":
    st.markdown("<h2 style='font-family: san-serif; text-align: center; color: #261324; \
                 font-weight: 550;'>Top-100 most positive comments</h2>", unsafe_allow_html=True)

    st.info('Only comments with a sentiment score above 0.85 are displayed.', icon='‚ÑπÔ∏è')

    if "df_sentiment" not in st.session_state or st.session_state["df_sentiment"] is None:
        st.warning("No data available. Please provide a link and fetch comments first.", icon='‚ö†Ô∏è')
    else:
        topPos_df = show_positive_comments(st.session_state["df_sentiment"])
        st.dataframe(data=topPos_df, use_container_width=True)

elif st.session_state["page"] == "function_3":
    st.markdown("<h2 style='font-family: san-serif; text-align: center; color: #261324; \
                     font-weight: 550;'>Top-100 most negative comments</h2>", unsafe_allow_html=True)
    st.info('Only comments with a sentiment score above 0.85 are displayed.', icon='‚ÑπÔ∏è')

    if "df_sentiment" not in st.session_state or st.session_state["df_sentiment"] is None:
        st.warning("No data available. Please provide a link and fetch comments first.", icon='‚ö†Ô∏è')
    else:
        topNeg_df = show_negative_comments(st.session_state["df_sentiment"])
        st.dataframe(data=topNeg_df, use_container_width=True)

elif st.session_state["page"] == "function_4":
    st.markdown("<h2 style='font-family: san-serif; text-align: center; color: #261324; \
                         font-weight: 550;'>Show all comments</h2>", unsafe_allow_html=True)

    if "df_sentiment" not in st.session_state or st.session_state["df_sentiment"] is None:
        st.warning("No data available. Please provide a link and fetch comments first.", icon='‚ö†Ô∏è')
    else:
        st.dataframe(data=st.session_state["df_sentiment"][['author', 'comment', 'date', 'likes']],
                     use_container_width=True)


elif st.session_state["page"] == "function_5":
    st.markdown("<h2 style='font-family: san-serif; text-align: center; color: #261324; \
                             font-weight: 550;'>Sentiment Distribution Visualization</h2>", unsafe_allow_html=True)

    st.write("Select sentiments to display:")

    # –û–ø—Ü—ñ—ó –¥–ª—è –≤–∏–±–æ—Ä—É
    sentiment_options = ["negative", "neutral", "positive"]

    # –†–æ–∑–º—ñ—â–µ–Ω–Ω—è —á–µ–∫–±–æ–∫—Å—ñ–≤ –≤ –æ–¥–∏–Ω —Ä—è–¥–æ–∫
    cols = st.columns(len(sentiment_options))
    selected_sentiments = []

    for col, sentiment in zip(cols, sentiment_options):
        with col:
            if st.checkbox(sentiment, value=True):
                selected_sentiments.append(sentiment)

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö
    if "df_sentiment" not in st.session_state or st.session_state["df_sentiment"] is None:
        st.error("No data available for visualization. Please provide a link and fetch comments first.", icon='‚ùóÔ∏è')
    elif not selected_sentiments:
        st.warning("Select at least one sentiment to display.", icon='‚ö†Ô∏è')
    else:
        # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
        filtered_df = st.session_state["df_sentiment"][
            st.session_state["df_sentiment"]["dominant_sentiment"].isin(selected_sentiments)
        ]

        if filtered_df.empty:
            st.warning("No data available for the selected sentiments.", icon='‚ö†Ô∏è')
        else:
            # –°–ø—ñ–Ω–µ—Ä –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –ø–æ–±—É–¥–æ–≤–∏ –≥—Ä–∞—Ñ—ñ–∫—ñ–≤
            with st.spinner("Analyzing sentiment distribution..."):
                time.sleep(2)
                sentiments_count = count_classes(filtered_df)
                sentiments_disribution_graph = plot_sentiment_analysis(sentiments_count)
                st.plotly_chart(sentiments_disribution_graph, use_container_width=True, theme=None)

            st.markdown("<h2 style='font-family: san-serif; text-align: center; color: #261324; \
                                         font-weight: 550;'>ANOVA Test and Comment Length Chart</h2>",
                        unsafe_allow_html=True)

            with st.spinner("Processing ANOVA test..."):
                anova_test = perform_anova_test(st.session_state["df_sentiment"])
                st.info(anova_test, icon='‚ÑπÔ∏è')

            with st.spinner("Generating comment length chart..."):
                time.sleep(2)
                comments_length_graph = plot_comments_length_analysis(filtered_df)
                st.plotly_chart(comments_length_graph, use_container_width=True, theme=None)


elif st.session_state["page"] == "function_6":
    st.markdown("<h2 style='font-family: san-serif; text-align: center; color: #261324; \
                                             font-weight: 550;'>Frequent Words Visualization</h2>",
                unsafe_allow_html=True)

    if "df_clean_sentiment" not in st.session_state or st.session_state["df_clean_sentiment"] is None:
        st.error("No data available for visualization. Please provide a link and fetch comments first.", icon='‚ùóÔ∏è')
    else:
        df_fr_an = create_df_for_fa(st.session_state["df_clean_sentiment"])
        frequent_words = frequent_words(df_fr_an)

        # –°–≤—ñ—Ç—á–µ—Ä –¥–ª—è –≤–∏–±–æ—Ä—É –≥—Ä–∞—Ñ—ñ–∫–∞
        chart_type = st.selectbox(
            "Select chart type:",
            ["Word Cloud", "Noun Frequencies", "Verb Frequencies", "Adjective Frequencies"]
        )

        # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤–∏–±–æ—Ä—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        if chart_type == "Word Cloud":
            with st.spinner("Generating word cloud..."):
                time.sleep(3)
                wordcloud = generate_wordcloud(df_fr_an)
            if wordcloud:
                st.pyplot(wordcloud, use_container_width=True)
            else:
                st.warning("I`m sorry. Word cloud could not be generated.", icon='‚ö†Ô∏è')

        elif chart_type == "Noun Frequencies":
            with st.spinner("Generating noun frequency chart..."):
                time.sleep(3)
                nouns_plot = plot_word_frequencies(frequent_words[0])  # nouns
            if nouns_plot:
                st.plotly_chart(nouns_plot, use_container_width=True, theme=None)
            else:
                st.warning("I`m sorry. No noun frequencies available.", icon='‚ö†Ô∏è')

        elif chart_type == "Verb Frequencies":
            with st.spinner("Generating verb frequency chart..."):
                time.sleep(3)
                verbs_plot = plot_word_frequencies(frequent_words[1])  # verbs
            if verbs_plot:
                st.plotly_chart(verbs_plot, use_container_width=True, theme=None)
            else:
                st.warning("I`m sorry. No verb frequencies available.", icon='‚ö†Ô∏è')

        elif chart_type == "Adjective Frequencies":
            with st.spinner("Generating adjective frequency chart..."):
                time.sleep(3)
                adjectives_plot = plot_word_frequencies(frequent_words[2])  # adjectives
            if adjectives_plot:
                st.plotly_chart(adjectives_plot, use_container_width=True, theme=None)
            else:
                st.warning("I`m sorry. No adjective frequencies available.", icon='‚ö†Ô∏è')
